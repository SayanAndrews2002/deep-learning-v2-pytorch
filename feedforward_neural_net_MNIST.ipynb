{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SayanAndrews2002/deep-learning-v2-pytorch/blob/master/feedforward_neural_net_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFcNGlLobLZN"
      },
      "source": [
        "## Intro\n",
        "Below is a simple example of a feedforward neural network implemented using PyTorch. This network is designed for a generic classification task, where the goal is to predict the class of an input vector. The network consists of an input layer, a few hidden layers, and an output layer. The exact number of layers and their sizes can be adjusted based on the specific requirements of your task."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU"
      ],
      "metadata": {
        "id": "t489OR-wGZIS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "Zl9CSQiYG98a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dcd84a7-7db9-4b72-fc55-e53ff9cbef1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Create a W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Create an account here: https://wandb.ai/authorize?signup=true&ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: After creating your account, create a new API key and store it securely.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste your API key and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msjandrew\u001b[0m (\u001b[33msjandrew-university-of-california-irvine\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JWSDGcM8fPzE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GE--hQPqs_2_"
      },
      "source": [
        "### Check GPU availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Zt89xrC4sHt0"
      },
      "outputs": [],
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY6V-tL7fWTr",
        "outputId": "2f9bd207-d8e4-484e-81ad-147a84899b3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFCHe-BPa5Hm"
      },
      "source": [
        "## Define a feedforward neural net model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "POtVCrhoajYo"
      },
      "outputs": [],
      "source": [
        "class FeedforwardNeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(FeedforwardNeuralNet, self).__init__()\n",
        "        # First hidden layer\n",
        "        self.hidden1 = nn.Linear(input_size, hidden_size)\n",
        "        # Second hidden layer\n",
        "        self.hidden2 = nn.Linear(hidden_size, hidden_size)\n",
        "        # Output layer\n",
        "        self.output = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass through the first hidden layer with ReLU activation\n",
        "        x = F.relu(self.hidden1(x))\n",
        "        # Forward pass through the second hidden layer with ReLU activation\n",
        "        x = F.relu(self.hidden2(x))\n",
        "        # Forward pass through the output layer\n",
        "        x = self.output(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmGhHF2ws7W5"
      },
      "source": [
        "### Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ljCaUcrMs0G-"
      },
      "outputs": [],
      "source": [
        "# model hyper-parameters\n",
        "input_size = 784  # For MNIST dataset, for example\n",
        "hidden_size = 500 # Number of hidden neurons\n",
        "num_classes = 10  # Number of output classes (e.g., MNIST has 10 digits)\n",
        "\n",
        "# training hyper-parameters\n",
        "num_epochs = 5\n",
        "batch_size = 100\n",
        "learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0V0cryvGUsN"
      },
      "source": [
        "### Weights & Biases (wandb) setup\n",
        "\n",
        "We load the API key from `.env` and initialize a W&B run to track:\n",
        "\n",
        "- Training batch loss and epoch-level loss/accuracy\n",
        "- Test loss and accuracy per epoch\n",
        "- Learning rate and key hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-ssYkmOoGUsN"
      },
      "outputs": [],
      "source": [
        "# def load_env(path=\".env\"):\n",
        "#     env_path = Path(path)\n",
        "#     if not env_path.exists():\n",
        "#         print(f\"No {path} file found. W&B logging will be disabled.\")\n",
        "#         return\n",
        "\n",
        "#     for line in env_path.read_text().splitlines():\n",
        "#         line = line.strip()\n",
        "#         if not line or line.startswith(\"#\") or \"=\" not in line:\n",
        "#             continue\n",
        "#         key, value = line.split(\"=\", 1)\n",
        "#         os.environ.setdefault(key.strip(), value.strip())\n",
        "\n",
        "\n",
        "# load_env(\".env\")\n",
        "# wandb_key = os.getenv(\"WANDB_API_KEY\")\n",
        "# wandb_project = os.getenv(\"WANDB_PROJECT\", \"cs273p\")\n",
        "\n",
        "# # Avoid saving notebook code snapshots (keeps setup lightweight for class use).\n",
        "# os.environ.setdefault(\"WANDB_DISABLE_CODE\", \"true\")\n",
        "\n",
        "# if not wandb_key:\n",
        "#     print(\"WANDB_API_KEY not set; running without W&B logging.\")\n",
        "#     wandb.init(project=wandb_project, mode=\"disabled\")\n",
        "# else:\n",
        "#     os.environ[\"WANDB_API_KEY\"] = wandb_key\n",
        "#     os.environ.setdefault(\"WANDB_PROJECT\", wandb_project)\n",
        "#     wandb.login()\n",
        "#     wandb.init(\n",
        "#         project=wandb_project,\n",
        "#         name=\"feedforward-mnist\",\n",
        "#         config={\n",
        "#             \"input_size\": input_size,\n",
        "#             \"hidden_size\": hidden_size,\n",
        "#             \"num_classes\": num_classes,\n",
        "#             \"num_epochs\": num_epochs,\n",
        "#             \"batch_size\": batch_size,\n",
        "#             \"learning_rate\": learning_rate,\n",
        "#         },\n",
        "#     )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project=\"cs273p\",\n",
        "    name=\"feedforward-mnist\",\n",
        "    config={\n",
        "        \"input_size\": input_size,\n",
        "        \"hidden_size\": hidden_size,\n",
        "        \"num_classes\": num_classes,\n",
        "        \"num_epochs\": num_epochs,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"learning_rate\": learning_rate,\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "RZxfrncrGWQb",
        "outputId": "aeff37e7-9c00-4d7f-f807-b7faef10bf27"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260212_054328-765646iy</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sjandrew-university-of-california-irvine/cs273p/runs/765646iy' target=\"_blank\">feedforward-mnist</a></strong> to <a href='https://wandb.ai/sjandrew-university-of-california-irvine/cs273p' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sjandrew-university-of-california-irvine/cs273p' target=\"_blank\">https://wandb.ai/sjandrew-university-of-california-irvine/cs273p</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sjandrew-university-of-california-irvine/cs273p/runs/765646iy' target=\"_blank\">https://wandb.ai/sjandrew-university-of-california-irvine/cs273p/runs/765646iy</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sjandrew-university-of-california-irvine/cs273p/runs/765646iy?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7ac180f22d80>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz_DIU_5bDkN",
        "outputId": "9e7d7cda-3237-4491-8ead-d7acaa3bf5c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FeedforwardNeuralNet(\n",
            "  (hidden1): Linear(in_features=784, out_features=500, bias=True)\n",
            "  (hidden2): Linear(in_features=500, out_features=500, bias=True)\n",
            "  (output): Linear(in_features=500, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Create the neural network\n",
        "model = FeedforwardNeuralNet(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Track gradients and parameter updates in W&B\n",
        "wandb.watch(model, log=\"all\", log_freq=100)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm9spj5Fb5hM"
      },
      "source": [
        "**Explanation of the code**\n",
        "\n",
        "This code defines a neural network (`FeedforwardNeuralNet`) with two hidden layers, each followed by a ReLU activation function.\n",
        "\n",
        "The `__init__` method initializes the layers of the network, and the `forward` method defines how the data flows through the network, i.e., it specifies the forward pass.\n",
        "\n",
        "- `input_size`: The size of the input features (e.g., for the MNIST dataset, this would be 28x28=784, assuming you flatten the images into a 784-dimensional vector).\n",
        "- `hidden_size`: The number of neurons in each hidden layer. You can adjust this based on the complexity of your task.\n",
        "- `num_classes`: The number of output classes for your classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-NnJw6Cs2B7"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vnrhtrekfNHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f74c5ce-d7d3-497d-84e3-c901332c3155"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 12.6MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 334kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.21MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.29MB/s]\n"
          ]
        }
      ],
      "source": [
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnYLrSQ0sdo7"
      },
      "source": [
        "### Check the data and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnMfEressM9p",
        "outputId": "49adf480-9e97-4e80-daa1-e1c41b572d64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "print(images.shape, labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "b-S6w8tysho6",
        "outputId": "4b039bca-3b6a-4044-efa1-842d3948cee0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ac180e93260>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAG2hJREFUeJzt3X1slfX9//HXKdADSnuwlPb0cGdBhUUsmyhdg9woDaXbGHdZsPOPshgRLThk6tJlAs4l3VjyncEwddkGmgkCyYBIXBMttmRbwXAXQrY1lHS2DFpmM86BAoW0n98f/DzzSAte5Zy+T8vzkXySnuu63r3efLg4r17nurjqc845AQDQy1KsGwAA3J4IIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgYaN3Al3V2dur06dNKS0uTz+ezbgcA4JFzTufPn1coFFJKSvfnOUkXQKdPn9bo0aOt2wAA3KKmpiaNGjWq2/VJ9xFcWlqadQsAgDi42ft5wgJo48aNuvvuuzV48GDl5+frk08++Up1fOwGAP3Dzd7PExJA27Zt0+rVq7V27VodPnxYkydPVlFRkc6ePZuI3QEA+iKXAFOnTnVlZWXR1x0dHS4UCrmKioqb1obDYSeJwWAwGH18hMPhG77fx/0M6MqVKzp06JAKCwujy1JSUlRYWKja2trrtm9vb1ckEokZAID+L+4B9Nlnn6mjo0PZ2dkxy7Ozs9Xc3Hzd9hUVFQoEAtHBHXAAcHswvwuuvLxc4XA4OpqamqxbAgD0grj/P6DMzEwNGDBALS0tMctbWloUDAav297v98vv98e7DQBAkov7GVBqaqqmTJmiqqqq6LLOzk5VVVWpoKAg3rsDAPRRCXkSwurVq1VaWqqHHnpIU6dO1Wuvvaa2tjb94Ac/SMTuAAB9UEICaMmSJfrPf/6jNWvWqLm5WV//+tdVWVl53Y0JAIDbl88556yb+KJIJKJAIGDdBgDgFoXDYaWnp3e73vwuOADA7YkAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJhDwNG0ByKCkp6VHdSy+95LkmLy/Pc81jjz3muaampsZzDZITZ0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABM+55yzbuKLIpGIAoGAdRtAQr3++uuea7773e96rhkxYoTnGklKTU3tUZ1XbW1tnmuWLFniuaaystJzDW5dOBxWenp6t+s5AwIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGBioHUDQDLx+/2ea9atW+e55tlnn/Vc05PnBh8/ftxzjSRt2bLFc83KlSs914RCIc81paWlnmt4GGly4gwIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACR5GCnzB8OHDPdcsX748AZ1c789//rPnmqVLl/ZoX62trZ5rBg8e7Llm7dq1nmvQf3AGBAAwQQABAEzEPYDWrVsnn88XMyZOnBjv3QAA+riEXAO6//779dFHH/1vJwO51AQAiJWQZBg4cKCCwWAivjUAoJ9IyDWgEydOKBQKady4cXriiSfU2NjY7bbt7e2KRCIxAwDQ/8U9gPLz87V582ZVVlbqjTfeUENDg6ZPn67z5893uX1FRYUCgUB0jB49Ot4tAQCSUNwDqLi4WN/73veUl5enoqIiffDBBzp37py2b9/e5fbl5eUKh8PR0dTUFO+WAABJKOF3BwwbNkz33Xef6uvru1zv9/vl9/sT3QYAIMkk/P8BXbhwQSdPnlROTk6idwUA6EPiHkAvvPCCampq9K9//Ut/+9vftHDhQg0YMEAlJSXx3hUAoA+L+0dwp06dUklJiVpbWzVixAg98sgj2r9/v0aMGBHvXQEA+jCfc85ZN/FFkUhEgUDAug3gK5s5c6bnmm984xuea373u995rrlw4YLnmt7U0dHhuaa7G5puhE9gbITDYaWnp3e7nmfBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMJHwX0gH9Hc1NTW9UtMfpaR4/xnY5/MloBNY4AwIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCp2EDMNPZ2em5xjmXgE5ggTMgAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACY8B9C+ffs0b948hUIh+Xw+7dq1K2a9c05r1qxRTk6OhgwZosLCQp04cSJe/QIA+gnPAdTW1qbJkydr48aNXa5fv369NmzYoDfffFMHDhzQnXfeqaKiIl2+fPmWmwUA9B8DvRYUFxeruLi4y3XOOb322mv66U9/qvnz50uS3nnnHWVnZ2vXrl16/PHHb61bAEC/EddrQA0NDWpublZhYWF0WSAQUH5+vmpra7usaW9vVyQSiRkAgP4vrgHU3NwsScrOzo5Znp2dHV33ZRUVFQoEAtExevToeLYEAEhS5nfBlZeXKxwOR0dTU5N1SwCAXhDXAAoGg5KklpaWmOUtLS3RdV/m9/uVnp4eMwAA/V9cAyg3N1fBYFBVVVXRZZFIRAcOHFBBQUE8dwUA6OM83wV34cIF1dfXR183NDTo6NGjysjI0JgxY7Rq1Sr9/Oc/17333qvc3Fy9/PLLCoVCWrBgQTz7BgD0cZ4D6ODBg3r00Uejr1evXi1JKi0t1ebNm/XSSy+pra1Ny5Yt07lz5/TII4+osrJSgwcPjl/XAIA+z+ecc9ZNfFEkElEgELBuA0Av6Ojo8Fyzfft2zzUlJSWea3DrwuHwDa/rm98FBwC4PRFAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATHj+dQzArejJw9c7OzsT0EnXNm7c6LnmueeeS0Anfc/MmTM916SkeP8Z2Ofzea5BcuIMCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkeRgrdcccdPap76623PNf05MGiPXmAaU89/fTTnmvmz5/vueaFF17wXLNnzx7PNZcuXfJcI0nFxcWea7Zu3eq5JtmPByQWZ0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBM8DBS6MEHH+xRXUlJSZw7sTdgwADPNSNHjvRc895773mu+cMf/uC5pqqqynONJG3YsMFzzdChQ3u0L68+/fTTXtkPEo8zIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACZ8zjln3cQXRSIRBQIB6zZuK9u2betR3eLFiz3X+Hw+zzUffPCB55q3337bc40klZaWeq4pLi72XNOTeUiyf6pxsWXLFs81Tz/9tOeaS5cuea7BrQuHw0pPT+92PWdAAAATBBAAwITnANq3b5/mzZunUCgkn8+nXbt2xaxfunSpfD5fzJg7d268+gUA9BOeA6itrU2TJ0/Wxo0bu91m7ty5OnPmTHRs3br1lpoEAPQ/nn8janFx8U0vuvr9fgWDwR43BQDo/xJyDai6ulpZWVmaMGGCnnnmGbW2tna7bXt7uyKRSMwAAPR/cQ+guXPn6p133lFVVZV++ctfqqamRsXFxero6Ohy+4qKCgUCgegYPXp0vFsCACQhzx/B3czjjz8e/fqBBx5QXl6exo8fr+rqas2ePfu67cvLy7V69ero60gkQggBwG0g4bdhjxs3TpmZmaqvr+9yvd/vV3p6eswAAPR/CQ+gU6dOqbW1VTk5OYneFQCgD/H8EdyFCxdizmYaGhp09OhRZWRkKCMjQ6+88ooWL16sYDCokydP6qWXXtI999yjoqKiuDYOAOjbPAfQwYMH9eijj0Zff379prS0VG+88YaOHTumt99+W+fOnVMoFNKcOXP06quvyu/3x69rAECfx8NIkfQPIx0zZoznmn//+9+eayQpLS3Nc82XnwbyVcyaNctzTZL9U73O7t27Pdf05BhC38HDSAEASYkAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYCLuv5IbfU9PnlDd07qUlP73M09P/kw9qens7PRc05sWLFhg3QL6mP73bgAA6BMIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCY4GGkkHOu1+p68kDN3/72t55rqqurPddI0nPPPee5Jicnx3NNT+ahp39PyayxsdFzzbJlyzzXVFZWeq5B4nEGBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwITPJdkTDiORiAKBgHUbt5WHHnqoR3U7d+70XBMKhTzXJNkhGhe1tbWea1599VXPNXfddZfnGknasGGD55rhw4d7rvH5fJ5rtm/f7rmmpKTEcw1uXTgcVnp6erfrOQMCAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgYqB1A7B38ODBHtV95zvf8Vxz+PDhHu2rt7S2tnquuXjxouea6dOne67pTeFw2HPN1q1bPdfc6EGV6P84AwIAmCCAAAAmPAVQRUWFHn74YaWlpSkrK0sLFixQXV1dzDaXL19WWVmZhg8frqFDh2rx4sVqaWmJa9MAgL7PUwDV1NSorKxM+/fv14cffqirV69qzpw5amtri27z/PPP6/3339eOHTtUU1Oj06dPa9GiRXFvHADQt3m6CaGysjLm9ebNm5WVlaVDhw5pxowZCofD+v3vf68tW7bosccekyRt2rRJX/va17R//35985vfjF/nAIA+7ZauAX1+p0xGRoYk6dChQ7p69aoKCwuj20ycOFFjxozp9lcQt7e3KxKJxAwAQP/X4wDq7OzUqlWrNG3aNE2aNEmS1NzcrNTUVA0bNixm2+zsbDU3N3f5fSoqKhQIBKJj9OjRPW0JANCH9DiAysrKdPz4cb333nu31EB5ebnC4XB0NDU13dL3AwD0DT36j6grVqzQnj17tG/fPo0aNSq6PBgM6sqVKzp37lzMWVBLS4uCwWCX38vv98vv9/ekDQBAH+bpDMg5pxUrVmjnzp3au3evcnNzY9ZPmTJFgwYNUlVVVXRZXV2dGhsbVVBQEJ+OAQD9gqczoLKyMm3ZskW7d+9WWlpa9LpOIBDQkCFDFAgE9OSTT2r16tXKyMhQenq6Vq5cqYKCAu6AAwDE8BRAb7zxhiRp1qxZMcs3bdqkpUuXSpJ+/etfKyUlRYsXL1Z7e7uKior0m9/8Ji7NAgD6D59zzlk38UWRSESBQMC6DSTIqlWrPNfk5eV5rvnvf//ruUb63w9ZXtTX1/doX/3NzJkzPdfs3bvXc8327ds915SUlHiuwa0Lh8M3fOAsz4IDAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJjgadgAgITgadgAgKREAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAw4SmAKioq9PDDDystLU1ZWVlasGCB6urqYraZNWuWfD5fzFi+fHlcmwYA9H2eAqimpkZlZWXav3+/PvzwQ129elVz5sxRW1tbzHZPPfWUzpw5Ex3r16+Pa9MAgL5voJeNKysrY15v3rxZWVlZOnTokGbMmBFdfscddygYDManQwBAv3RL14DC4bAkKSMjI2b5u+++q8zMTE2aNEnl5eW6ePFit9+jvb1dkUgkZgAAbgOuhzo6Oty3v/1tN23atJjlb731lqusrHTHjh1zf/zjH93IkSPdwoULu/0+a9eudZIYDAaD0c9GOBy+YY70OICWL1/uxo4d65qamm64XVVVlZPk6uvru1x/+fJlFw6Ho6Opqcl80hgMBoNx6+NmAeTpGtDnVqxYoT179mjfvn0aNWrUDbfNz8+XJNXX12v8+PHXrff7/fL7/T1pAwDQh3kKIOecVq5cqZ07d6q6ulq5ubk3rTl69KgkKScnp0cNAgD6J08BVFZWpi1btmj37t1KS0tTc3OzJCkQCGjIkCE6efKktmzZom9961saPny4jh07pueff14zZsxQXl5eQv4AAIA+yst1H3XzOd+mTZucc841Nja6GTNmuIyMDOf3+90999zjXnzxxZt+DvhF4XDY/HNLBoPBYNz6uNl7v+//B0vSiEQiCgQC1m0AAG5ROBxWenp6t+t5FhwAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwETSBZBzzroFAEAc3Oz9POkC6Pz589YtAADi4Gbv5z6XZKccnZ2dOn36tNLS0uTz+WLWRSIRjR49Wk1NTUpPTzfq0B7zcA3zcA3zcA3zcE0yzINzTufPn1coFFJKSvfnOQN7saevJCUlRaNGjbrhNunp6bf1AfY55uEa5uEa5uEa5uEa63kIBAI33SbpPoIDANweCCAAgIk+FUB+v19r166V3++3bsUU83AN83AN83AN83BNX5qHpLsJAQBwe+hTZ0AAgP6DAAIAmCCAAAAmCCAAgIk+E0AbN27U3XffrcGDBys/P1+ffPKJdUu9bt26dfL5fDFj4sSJ1m0l3L59+zRv3jyFQiH5fD7t2rUrZr1zTmvWrFFOTo6GDBmiwsJCnThxwqbZBLrZPCxduvS642Pu3Lk2zSZIRUWFHn74YaWlpSkrK0sLFixQXV1dzDaXL19WWVmZhg8frqFDh2rx4sVqaWkx6jgxvso8zJo167rjYfny5UYdd61PBNC2bdu0evVqrV27VocPH9bkyZNVVFSks2fPWrfW6+6//36dOXMmOv7yl79Yt5RwbW1tmjx5sjZu3Njl+vXr12vDhg168803deDAAd15550qKirS5cuXe7nTxLrZPEjS3LlzY46PrVu39mKHiVdTU6OysjLt379fH374oa5evao5c+aora0tus3zzz+v999/Xzt27FBNTY1Onz6tRYsWGXYdf19lHiTpqaeeijke1q9fb9RxN1wfMHXqVFdWVhZ93dHR4UKhkKuoqDDsqvetXbvWTZ482boNU5Lczp07o687OztdMBh0v/rVr6LLzp075/x+v9u6datBh73jy/PgnHOlpaVu/vz5Jv1YOXv2rJPkampqnHPX/u4HDRrkduzYEd3mH//4h5PkamtrrdpMuC/Pg3POzZw50/3whz+0a+orSPozoCtXrujQoUMqLCyMLktJSVFhYaFqa2sNO7Nx4sQJhUIhjRs3Tk888YQaGxutWzLV0NCg5ubmmOMjEAgoPz//tjw+qqurlZWVpQkTJuiZZ55Ra2urdUsJFQ6HJUkZGRmSpEOHDunq1asxx8PEiRM1ZsyYfn08fHkePvfuu+8qMzNTkyZNUnl5uS5evGjRXreS7mGkX/bZZ5+po6ND2dnZMcuzs7P1z3/+06grG/n5+dq8ebMmTJigM2fO6JVXXtH06dN1/PhxpaWlWbdnorm5WZK6PD4+X3e7mDt3rhYtWqTc3FydPHlSP/nJT1RcXKza2loNGDDAur246+zs1KpVqzRt2jRNmjRJ0rXjITU1VcOGDYvZtj8fD13NgyR9//vf19ixYxUKhXTs2DH9+Mc/Vl1dnf70pz8Zdhsr6QMI/1NcXBz9Oi8vT/n5+Ro7dqy2b9+uJ5980rAzJIPHH388+vUDDzygvLw8jR8/XtXV1Zo9e7ZhZ4lRVlam48eP3xbXQW+ku3lYtmxZ9OsHHnhAOTk5mj17tk6ePKnx48f3dptdSvqP4DIzMzVgwIDr7mJpaWlRMBg06io5DBs2TPfdd5/q6+utWzHz+THA8XG9cePGKTMzs18eHytWrNCePXv08ccfx/z6lmAwqCtXrujcuXMx2/fX46G7eehKfn6+JCXV8ZD0AZSamqopU6aoqqoquqyzs1NVVVUqKCgw7MzehQsXdPLkSeXk5Fi3YiY3N1fBYDDm+IhEIjpw4MBtf3ycOnVKra2t/er4cM5pxYoV2rlzp/bu3avc3NyY9VOmTNGgQYNijoe6ujo1Njb2q+PhZvPQlaNHj0pSch0P1ndBfBXvvfee8/v9bvPmze7vf/+7W7ZsmRs2bJhrbm62bq1X/ehHP3LV1dWuoaHB/fWvf3WFhYUuMzPTnT171rq1hDp//rw7cuSIO3LkiJPk/u///s8dOXLEffrpp845537xi1+4YcOGud27d7tjx465+fPnu9zcXHfp0iXjzuPrRvNw/vx598ILL7ja2lrX0NDgPvroI/fggw+6e++9112+fNm69bh55plnXCAQcNXV1e7MmTPRcfHixeg2y5cvd2PGjHF79+51Bw8edAUFBa6goMCw6/i72TzU19e7n/3sZ+7gwYOuoaHB7d69240bN87NmDHDuPNYfSKAnHPu9ddfd2PGjHGpqalu6tSpbv/+/dYt9bolS5a4nJwcl5qa6kaOHOmWLFni6uvrrdtKuI8//thJum6UlpY6567div3yyy+77Oxs5/f73ezZs11dXZ1t0wlwo3m4ePGimzNnjhsxYoQbNGiQGzt2rHvqqaf63Q9pXf35JblNmzZFt7l06ZJ79tln3V133eXuuOMOt3DhQnfmzBm7phPgZvPQ2NjoZsyY4TIyMpzf73f33HOPe/HFF104HLZt/Ev4dQwAABNJfw0IANA/EUAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMPH/AKHBzHKqdpKKAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(images[1,0,:,:], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58yoIgrvssPs"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qQgNgTnwdUH0"
      },
      "outputs": [],
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, device, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images = images.view(images.size(0), -1).to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = 100 * correct / total\n",
        "    model.train()\n",
        "    return avg_loss, accuracy"
      ],
      "metadata": {
        "id": "2sL7PkfIG2tD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR0rH5GFfJbY",
        "outputId": "d1312d7a-9bfd-423d-d63e-7d4337fb0d72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 0.2016\n",
            "Epoch [1/5], Step [200/600], Loss: 0.3039\n",
            "Epoch [1/5], Step [300/600], Loss: 0.0933\n",
            "Epoch [1/5], Step [400/600], Loss: 0.1447\n",
            "Epoch [1/5], Step [500/600], Loss: 0.1488\n",
            "Epoch [1/5], Step [600/600], Loss: 0.1132\n",
            "Epoch [1/5] Train Loss: 0.2535, Train Acc: 92.68% | Test Loss: 0.1080, Test Acc: 96.45%\n",
            "Epoch [2/5], Step [100/600], Loss: 0.0866\n",
            "Epoch [2/5], Step [200/600], Loss: 0.1046\n",
            "Epoch [2/5], Step [300/600], Loss: 0.0865\n",
            "Epoch [2/5], Step [400/600], Loss: 0.0557\n",
            "Epoch [2/5], Step [500/600], Loss: 0.0280\n",
            "Epoch [2/5], Step [600/600], Loss: 0.0293\n",
            "Epoch [2/5] Train Loss: 0.0918, Train Acc: 97.05% | Test Loss: 0.0822, Test Acc: 97.53%\n",
            "Epoch [3/5], Step [100/600], Loss: 0.0489\n",
            "Epoch [3/5], Step [200/600], Loss: 0.0493\n",
            "Epoch [3/5], Step [300/600], Loss: 0.0704\n",
            "Epoch [3/5], Step [400/600], Loss: 0.0268\n",
            "Epoch [3/5], Step [500/600], Loss: 0.0540\n",
            "Epoch [3/5], Step [600/600], Loss: 0.0394\n",
            "Epoch [3/5] Train Loss: 0.0604, Train Acc: 98.11% | Test Loss: 0.0726, Test Acc: 97.84%\n",
            "Epoch [4/5], Step [100/600], Loss: 0.0124\n",
            "Epoch [4/5], Step [200/600], Loss: 0.0515\n",
            "Epoch [4/5], Step [300/600], Loss: 0.0289\n",
            "Epoch [4/5], Step [400/600], Loss: 0.0725\n",
            "Epoch [4/5], Step [500/600], Loss: 0.0080\n",
            "Epoch [4/5], Step [600/600], Loss: 0.1007\n",
            "Epoch [4/5] Train Loss: 0.0427, Train Acc: 98.66% | Test Loss: 0.0645, Test Acc: 98.10%\n",
            "Epoch [5/5], Step [100/600], Loss: 0.0199\n",
            "Epoch [5/5], Step [200/600], Loss: 0.0087\n",
            "Epoch [5/5], Step [300/600], Loss: 0.0265\n",
            "Epoch [5/5], Step [400/600], Loss: 0.0365\n",
            "Epoch [5/5], Step [500/600], Loss: 0.0024\n",
            "Epoch [5/5], Step [600/600], Loss: 0.0271\n",
            "Epoch [5/5] Train Loss: 0.0314, Train Acc: 99.02% | Test Loss: 0.0764, Test Acc: 97.83%\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model.train()\n",
        "total_step = len(train_loader)\n",
        "global_step = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss_sum = 0.0\n",
        "    epoch_correct = 0\n",
        "    epoch_total = 0\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Move tensors to the configured device\n",
        "        images = images.reshape(-1, 28 * 28).to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        global_step += 1\n",
        "        epoch_loss_sum += loss.item() * labels.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        epoch_correct += (predicted == labels).sum().item()\n",
        "        epoch_total += labels.size(0)\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
        "            wandb.log({\n",
        "                \"train/batch_loss\": loss.item(),\n",
        "                \"epoch\": epoch + 1,\n",
        "            }, step=global_step)\n",
        "\n",
        "    train_loss = epoch_loss_sum / epoch_total\n",
        "    train_acc = 100 * epoch_correct / epoch_total\n",
        "    test_loss, test_acc = evaluate(model, test_loader, device, criterion)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch [{epoch + 1}/{num_epochs}] \"\n",
        "        f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "        f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\"\n",
        "    )\n",
        "\n",
        "    wandb.log({\n",
        "        \"train/loss\": train_loss,\n",
        "        \"train/accuracy\": train_acc,\n",
        "        \"test/loss\": test_loss,\n",
        "        \"test/accuracy\": test_acc,\n",
        "        \"lr\": optimizer.param_groups[0][\"lr\"],\n",
        "        \"epoch\": epoch + 1,\n",
        "    }, step=global_step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zUBEh-YeDjT"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "We already log test loss and accuracy each epoch. The cell below re-runs evaluation to show the final metrics clearly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLvHHB1qerkq",
        "outputId": "78e629fc-1e64-43a8-b59d-fb09df14734d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Loss: 0.0764, Final Test Accuracy: 97.83%\n"
          ]
        }
      ],
      "source": [
        "final_test_loss, final_test_acc = evaluate(model, test_loader, device, criterion)\n",
        "print(f\"Final Test Loss: {final_test_loss:.4f}, Final Test Accuracy: {final_test_acc:.2f}%\")\n",
        "\n",
        "wandb.log({\n",
        "    \"test/final_loss\": final_test_loss,\n",
        "    \"test/final_accuracy\": final_test_acc,\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "g8f5kfBjfGDL"
      },
      "outputs": [],
      "source": [
        "# Save the model checkpoint\n",
        "# torch.save(model.state_dict(), 'models/model.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "ckxXn95kGUsO",
        "outputId": "35d42881-417d-43e0-a5ef-867bcdafd669"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▃▃▃▃▃▃▅▅▅▅▅▅▆▆▆▆▆▆██████</td></tr><tr><td>lr</td><td>▁▁▁▁▁</td></tr><tr><td>test/accuracy</td><td>▁▆▇█▇</td></tr><tr><td>test/final_accuracy</td><td>▁</td></tr><tr><td>test/final_loss</td><td>▁</td></tr><tr><td>test/loss</td><td>█▄▂▁▃</td></tr><tr><td>train/accuracy</td><td>▁▆▇██</td></tr><tr><td>train/batch_loss</td><td>▆█▃▄▄▄▃▃▃▂▂▂▂▂▃▂▂▂▁▂▂▃▁▃▁▁▂▂▁▂</td></tr><tr><td>train/loss</td><td>█▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5</td></tr><tr><td>lr</td><td>0.001</td></tr><tr><td>test/accuracy</td><td>97.83</td></tr><tr><td>test/final_accuracy</td><td>97.83</td></tr><tr><td>test/final_loss</td><td>0.07643</td></tr><tr><td>test/loss</td><td>0.07643</td></tr><tr><td>train/accuracy</td><td>99.02</td></tr><tr><td>train/batch_loss</td><td>0.02711</td></tr><tr><td>train/loss</td><td>0.03136</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">feedforward-mnist</strong> at: <a href='https://wandb.ai/sjandrew-university-of-california-irvine/cs273p/runs/765646iy' target=\"_blank\">https://wandb.ai/sjandrew-university-of-california-irvine/cs273p/runs/765646iy</a><br> View project at: <a href='https://wandb.ai/sjandrew-university-of-california-irvine/cs273p' target=\"_blank\">https://wandb.ai/sjandrew-university-of-california-irvine/cs273p</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20260212_054328-765646iy/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Close the W&B run\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkdUXmoCdszs"
      },
      "source": [
        "### Explanation of the code\n",
        "\n",
        "This notebook does the following:\n",
        "\n",
        "- Loads the MNIST dataset with `torchvision` and wraps it in data loaders.\n",
        "- Defines a simple two-hidden-layer feedforward network for digit classification.\n",
        "- Trains with mini-batches and evaluates at the end of each epoch.\n",
        "- Logs training and test loss/accuracy to W&B so you can monitor learning curves.\n",
        "\n",
        "Tune hyperparameters such as the learning rate, hidden size, and batch size based on your dataset and performance goals."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "feedforward_neural_net.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}